<h1 align="center" id="title">VisualSense</h1>

<p align="center">
  <img src="https://github.com/arul-5/visual-sense/assets/142246653/958a1342-dec3-4c68-807d-b0987be837cd" alt="VisualSense" width=80>
</p>


<p id="description">Welcome to the VisualSense repository! The problem being addressed by this project is the significant barrier faced by visually impaired individuals in comprehending visual content in their surroundings. Whether encountering images in real-time through a camera or uploading pictures for analysis, visually impaired individuals often struggle to understand the contents of these images without sighted assistance. This project seeks to bridge this gap by
developing a web application that utilizes Visual Question Answering (VQA) technology. Through VQA, users can interactively ask questions about images, enabling them to gain a better understanding of the visual content independently. By providing this tool, the project aims to enhance the accessibility of visual information for visually impaired individuals and promote their autonomy and inclusion.</p>

<h2>ðŸ›  Installation Steps:</h2>

<p>1. Front-End</p>


cd frontend




npm i



npm run dev


<p>2. Back-End</p>


cd backend



uvicorn index:app --reload


<h2>ðŸ’» Built with</h2>

Technologies used in the project:

*   PyTorch
*   FastAPI
*   NextJS
*   Hugging Faces Transformers
   
If you encounter any issues or have suggestions for improvements, please create an issue or pull request on GitHub.
